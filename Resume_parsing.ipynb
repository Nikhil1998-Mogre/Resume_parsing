{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b1d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4109a077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/', {'entities': [[1749, 1755, 'Companies worked at'], [1696, 1702, 'Companies worked at'], [1417, 1423, 'Companies worked at'], [1356, 1793, 'Skills'], [1209, 1215, 'Companies worked at'], [1136, 1247, 'Skills'], [928, 932, 'Graduation Year'], [858, 889, 'College Name'], [821, 856, 'Degree'], [787, 791, 'Graduation Year'], [744, 750, 'Companies worked at'], [722, 742, 'Designation'], [658, 664, 'Companies worked at'], [640, 656, 'Designation'], [574, 580, 'Companies worked at'], [555, 572, 'Designation'], [470, 493, 'Companies worked at'], [444, 468, 'Designation'], [308, 314, 'Companies worked at'], [234, 240, 'Companies worked at'], [175, 198, 'Companies worked at'], [93, 136, 'Email Address'], [39, 48, 'Location'], [13, 37, 'Designation'], [0, 12, 'Name']]}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# assuming the data is stored in a file called 'data.json'\n",
    "with open('C:/Spacy/train_data.json') as f:\n",
    "    cv_data = json.load(f)\n",
    "\n",
    "print(cv_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b911bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [[2275, 2281, 'Companies worked at'],\n",
       "  [2235, 2241, 'Companies worked at'],\n",
       "  [1603, 1609, 'Companies worked at'],\n",
       "  [667, 702, 'Skills'],\n",
       "  [639, 657, 'College Name'],\n",
       "  [612, 637, 'Degree'],\n",
       "  [592, 610, 'College Name'],\n",
       "  [587, 590, 'Degree'],\n",
       "  [568, 574, 'Companies worked at'],\n",
       "  [526, 536, 'Designation'],\n",
       "  [515, 524, 'Location'],\n",
       "  [507, 513, 'Companies worked at'],\n",
       "  [491, 503, 'Designation'],\n",
       "  [429, 438, 'Location'],\n",
       "  [352, 361, 'Location'],\n",
       "  [296, 305, 'Location'],\n",
       "  [270, 279, 'Location'],\n",
       "  [262, 268, 'Companies worked at'],\n",
       "  [246, 258, 'Designation'],\n",
       "  [238, 244, 'Companies worked at'],\n",
       "  [226, 236, 'Designation'],\n",
       "  [177, 207, 'Designation'],\n",
       "  [150, 155, 'Years of Experience'],\n",
       "  [54, 63, 'Location'],\n",
       "  [43, 52, 'Location'],\n",
       "  [35, 41, 'Companies worked at'],\n",
       "  [19, 31, 'Designation'],\n",
       "  [0, 18, 'Name']]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224a34fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[+] Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m[+] Saved config\u001b[0m\n",
      "C:\\Spacy\\config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config \"C:\\Spacy\\base_config.cfg\" \"C:\\Spacy\\config.cfg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0135dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spacy_doc(file,data):\n",
    "    nlp = spacy.blank('en')\n",
    "#     nlp = spacy.load(\"en_core_web_sm\")\n",
    "    db = DocBin()\n",
    "    \n",
    "    for text,annot in tqdm(data):\n",
    "        doc = nlp.make_doc(text)\n",
    "        annot = annot['entities']\n",
    "        \n",
    "        ents = []\n",
    "        entity_indices = []\n",
    "        \n",
    "        for start,end,label in annot:\n",
    "            skip_entity = False\n",
    "            for idx in range(start,end):\n",
    "                if idx in entity_indices:\n",
    "                    skip_entity=True\n",
    "                    break\n",
    "                    \n",
    "            if skip_entity==True:\n",
    "                continue\n",
    "                \n",
    "            entity_indices = entity_indices + list(range(start,end))\n",
    "            \n",
    "            try:\n",
    "                span =doc.char_span(start,end,label=label , alignment_mode='strict')\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            if span is None:\n",
    "                err_data = str([start,end]) + \"   \" +str(text) + \"\\n\"\n",
    "                file.write(err_data)\n",
    "                \n",
    "            else:\n",
    "                ents.append(span)\n",
    "                \n",
    "        try:\n",
    "            doc.ents = ents\n",
    "            db.add(doc)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c78e81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(cv_data,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c7d5f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 140/140 [00:02<00:00, 60.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 68.78it/s]\n"
     ]
    }
   ],
   "source": [
    "file = open('error.txt', 'w', encoding='utf-8', errors='ignore')\n",
    "\n",
    "\n",
    "db = get_spacy_doc(file, train)\n",
    "db.to_disk('train_data_2.spacy')\n",
    "\n",
    "db = get_spacy_doc(file, test)\n",
    "db.to_disk('test_data_2.spacy')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23968e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = DocBin().from_disk('train_data.spacy', exclude=['vocab']).to_disk('train_data.spacy', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eae75df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m[i] Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4m[i] Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m[+] Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4m[i] Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4m[i] Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00    164.04    0.00    0.00    0.00    0.00\n",
      "  0      20        340.66   4725.68    0.00    0.00    0.00    0.00\n",
      "  0      40         86.30    701.75    7.16   82.22    3.74    0.07\n",
      "  0      60        432.13    627.09    9.67   77.27    5.16    0.10\n",
      "  0      80        634.81   1580.92    9.27   72.06    4.95    0.09\n",
      "  0     100        480.53    926.06   13.32   78.26    7.28    0.13\n",
      "  0     120        244.68   1213.34   17.22   52.04   10.31    0.17\n",
      "  1     140         49.61    536.10   17.73   77.34   10.01    0.18\n",
      "  1     160         95.16    632.80   23.23   37.19   16.89    0.23\n",
      "  1     180        625.50   1174.63   14.70   34.98    9.30    0.15\n",
      "  1     200         61.14    583.63   21.79   35.21   15.77    0.22\n",
      "  1     220          9.78    339.94   24.05   73.96   14.36    0.24\n",
      "  1     240         46.19    610.02   35.18   45.93   28.51    0.35\n",
      "  1     260         21.29    441.31   39.22   55.45   30.33    0.39\n",
      "  2     280         13.99    412.35   27.80   41.78   20.83    0.28\n",
      "  2     300         11.48    384.94   37.47   66.49   26.09    0.37\n",
      "  2     320         43.30    467.91   33.01   52.54   24.06    0.33\n",
      "  2     340          8.85    352.27   33.66   55.45   24.17    0.34\n",
      "  2     360         21.78    442.59   38.94   51.94   31.14    0.39\n",
      "  2     380         69.85    358.16   41.32   53.72   33.57    0.41\n",
      "  2     400         19.28    364.29   42.65   54.12   35.19    0.43\n",
      "  3     420        146.64    349.26   48.01   52.86   43.98    0.48\n",
      "  3     440         10.33    433.12   50.20   50.36   50.05    0.50\n",
      "  3     460          7.99    318.09   39.69   48.96   33.37    0.40\n",
      "  3     480          5.98    262.46   41.47   59.43   31.85    0.41\n",
      "  3     500          7.23    242.80   40.70   50.52   34.07    0.41\n",
      "  3     520         31.72    417.68   38.04   54.86   29.12    0.38\n",
      "  3     540        105.59    281.33   37.67   60.22   27.40    0.38\n",
      "  4     560         57.01    375.65   41.45   59.32   31.85    0.41\n",
      "  4     580         19.67    323.27   34.72   66.01   23.56    0.35\n",
      "  4     600        137.05    482.93   30.59   68.18   19.72    0.31\n",
      "  4     620        622.67    376.18   38.11   63.08   27.30    0.38\n",
      "  4     640         32.38    292.22   43.25   54.63   35.79    0.43\n",
      "  4     660         16.54    304.02   42.83   53.31   35.79    0.43\n",
      "  4     680         15.20    370.51   35.79   51.92   27.30    0.36\n",
      "  5     700         11.51    271.86   40.58   57.51   31.34    0.41\n",
      "  5     720         22.74    252.44   41.30   62.50   30.84    0.41\n",
      "  5     740         16.85    231.82   43.95   56.91   35.79    0.44\n",
      "  5     760         16.27    420.18   42.50   61.90   32.36    0.42\n",
      "  5     780          9.64    340.48   46.47   56.16   39.64    0.46\n",
      "  5     800        607.18    310.36   41.70   53.22   34.28    0.42\n",
      "  5     820         12.82    236.62   44.38   43.68   45.10    0.44\n",
      "  6     840         21.30    259.11   43.52   62.22   33.47    0.44\n",
      "  6     860          7.60    217.10   47.56   60.12   39.33    0.48\n",
      "  6     880         11.24    288.01   47.49   56.14   41.15    0.47\n",
      "  6     900          9.95    213.87   43.56   57.98   34.88    0.44\n",
      "  6     920         28.87    268.79   42.00   65.38   30.94    0.42\n",
      "  6     940         12.17    244.12   47.24   64.67   37.21    0.47\n",
      "  6     960         22.70    362.90   44.15   63.74   33.77    0.44\n",
      "  7     980          7.04    169.48   45.14   62.93   35.19    0.45\n",
      "  7    1000          9.58    258.44   49.34   57.37   43.28    0.49\n",
      "\u001b[38;5;2m[+] Saved pipeline to output directory\u001b[0m\n",
      "output\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-03 16:44:54,480] [INFO] Set up nlp object from config\n",
      "[2023-04-03 16:44:54,500] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-04-03 16:44:54,507] [INFO] Created vocabulary\n",
      "[2023-04-03 16:44:58,185] [INFO] Added vectors: en_core_web_lg\n",
      "[2023-04-03 16:45:02,625] [INFO] Finished initializing nlp object\n",
      "[2023-04-03 16:45:15,196] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train \"C:\\Spacy\\config.cfg\" --output ./output --paths.train \"C:\\Users\\hp\\train_data.spacy\" --paths.dev \"C:\\Users\\hp\\test_data.spacy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe026d99",
   "metadata": {},
   "source": [
    "### MOdel Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d42adb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"C:/Users/hp/output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c48ada1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('my name is nikhil mogre. I worked at microsoft. I have 10 years of experience')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ceab027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my name is nikhil mogre. I worked at microsoft. I have 10 years of experience"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "838050e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name ---> Designation\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text,\"--->\",ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2f965",
   "metadata": {},
   "source": [
    "### New Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f166e1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyMuPDF\n",
      "  Downloading PyMuPDF-1.21.1-cp39-cp39-win_amd64.whl (11.7 MB)\n",
      "     ---------------------------------------- 11.7/11.7 MB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pyMuPDF\n",
      "Successfully installed pyMuPDF-1.21.1\n"
     ]
    }
   ],
   "source": [
    "# WHICH WILL READ PDF AND RETURN TEXT DATA \n",
    "!pip install pyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1ae1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c6340ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"C:/Users/hp/Downloads/Alice Clark CV.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b394241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cf8ec7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document('C:/Users/hp/Downloads/Alice Clark CV.pdf')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c909a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = [page.get_text() for page in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce397069",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\" \"\n",
    "for page in doc:\n",
    "    text = text + str(page.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f762726",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bccf100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87587751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice Clark AI / Machine Learning Delhi, India Email me on Indeed • 20+ years of experience in data handling, design, and development • Data Warehouse: Data analysis, star/snow flake scema data modelling and design specific to data warehousing and business intelligence • Database: Experience in database designing, scalability, back-up and recovery, writing and optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes. Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure, Stream Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake analytics(U-SQL) Willing to relocate anywhere WORK EXPERIENCE Software Engineer Microsoft – Bangalore, Karnataka January 2000 to Present 1. Microsoft Rewards Live dashboards: Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping online. Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft rewards website. Rewards live dashboards gives a live picture of usage world-wide and by markets like US, Canada, Australia, new user registration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations. the PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes. Technology/Tools used EDUCATION Indian Institute of Technology – Mumbai 2001 SKILLS Machine Learning, Natural Language Processing, and Big Data Handling ADDITIONAL INFORMATION Professional Skills • Excellent analytical, problem solving, communication, knowledge transfer and interpersonal skills with ability to interact with individuals at all the levels • Quick learner and maintains cordial relationship with project manager and team members and good performer both in team and independent job environments • Positive attitude towards superiors &amp; peers • Supervised junior developers throughout project lifecycle and provided technical assistance'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "394b6210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alice Clark \\nAI / Machine Learning \\n \\nDelhi, India Email me on Indeed \\n• \\n20+ years of experience in data handling, design, and development \\n• \\nData Warehouse: Data analysis, star/snow flake scema data modelling and design specific to \\ndata warehousing and business intelligence \\n• \\nDatabase: Experience in database designing, scalability, back-up and recovery, writing and \\noptimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes. \\nCloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure, \\nStream Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake \\nanalytics(U-SQL) \\nWilling to relocate anywhere \\n \\nWORK EXPERIENCE \\nSoftware Engineer \\nMicrosoft – Bangalore, Karnataka \\nJanuary 2000 to Present \\n1. Microsoft Rewards Live dashboards: \\nDescription: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping \\nonline. Microsoft Rewards members can earn points when searching with Bing, browsing with \\nMicrosoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft \\nStore. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft \\nrewards website. Rewards live dashboards gives a live picture of usage world-wide and by \\nmarkets like US, Canada, Australia, new user registration count, top/bottom performing rewards \\noffers, orders stats and weekly trends of user activities, orders and new user registrations. the \\nPBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes. \\nTechnology/Tools used \\n \\nEDUCATION \\nIndian Institute of Technology – Mumbai \\n2001 \\n \\nSKILLS \\nMachine Learning, Natural Language Processing, and Big Data Handling \\n \\n',\n",
       " 'ADDITIONAL INFORMATION \\nProfessional Skills \\n• Excellent analytical, problem solving, communication, knowledge transfer and interpersonal \\nskills with ability to interact with individuals at all the levels \\n• Quick learner and maintains cordial relationship with project manager and team members and \\ngood performer both in team and independent job environments \\n• Positive attitude towards superiors &amp; peers \\n• Supervised junior developers throughout project lifecycle and provided technical assistance \\n']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e4aa076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Clark ---> Name\n",
      "AI / Machine Learning ---> Designation\n",
      "Delhi ---> Location\n",
      "Microsoft ---> Companies worked at\n",
      "Software Engineer ---> Designation\n",
      "Microsoft ---> Companies worked at\n",
      "Microsoft ---> Companies worked at\n",
      "Microsoft ---> Companies worked at\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\"--->\",ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9155c6",
   "metadata": {},
   "source": [
    "### My Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d706ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"C:/Users/hp/Downloads/Nikhil-Mogre-Resume.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78d1889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d74e598c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document('C:/Users/hp/Downloads/Nikhil-Mogre-Resume.pdf')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1ccc6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\" \"\n",
    "for page in doc:\n",
    "    text = text + str(page.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac185c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bachelor of Engineering(ME)\n",
      "Job Analytics \n",
      "Playing chess ---> Degree\n",
      "Data Analyst ---> Designation\n",
      "SQL\n",
      "nikhilmogre1998@gmail.com\n",
      "linkedin.com/in/nikhilmogre/\n",
      "+91-9175440381\n",
      " ---> Skills\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\"--->\",ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b1b72",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8cc3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"C:/Users/hp/Downloads/Smith Resume.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "115ab6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38c1701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\" \"\n",
    "for page in doc:\n",
    "    text = text + str(page.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2e0ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indeed.com/r/falicent/140749dace5dc26f ---> Email Address\n",
      "Microsoft ---> Companies worked at\n",
      "Microsoft ---> Companies worked at\n",
      "Manchester ---> Location\n",
      "Microsoft ---> Companies worked at\n",
      "Microsoft ---> Companies worked at\n",
      "Microsoft ---> Companies worked at\n",
      "Microsoft ---> Companies worked at\n",
      "Microsoft ---> Companies worked at\n",
      "Microsoft ---> Companies worked at\n",
      "Microsoft ---> Companies worked at\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\"--->\",ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df34993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
